<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CSS文本溢出问题</title>
    <url>/2023/12/27/CSS%E6%96%87%E6%9C%AC%E6%BA%A2%E5%87%BA%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="问题："><a href="#问题：" class="headerlink" title="问题："></a><strong>问题</strong>：</h3><p>博客文章中 长链接&#x2F;长代码 超出浏览器窗口大小而无法完整显示（CSS文本溢出）</p>
<p>如下图所示：<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/12/27/r8v45hlTISMPyts.png"
                     
                ></p>
<h3 id="解决："><a href="#解决：" class="headerlink" title="解决："></a><strong>解决</strong>：</h3><p>打开 <code>themes\landscape\source\css\_partial\article.styl</code> 文件（该路径与所用主题有关），在 <code>.article-entry</code> 部分添加以下代码：</p>
<div class="highlight-container" data-rel="Stylus"><figure class="iseeu highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="attribute">word-break</span>: break-all	// 一个长长的单词不会新起一行展示，而是直接在本行剩余空间展示，展示不全时折断展示</span><br><span class="line"><span class="attribute">overflow-wrap</span>: break-word	// 一个长长的单词会新起一行展示，新的一行展示不全时折断展示</span><br></pre></td></tr></table></figure></div>



<h3 id="效果："><a href="#效果：" class="headerlink" title="效果："></a><strong>效果</strong>：</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/12/27/yt8ixFgBRpcrdeY.png"
                     
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/12/27/eziCIhA3ML7mWYy.png"
                     
                ></p>
<h3 id="One-more-thing"><a href="#One-more-thing" class="headerlink" title="One more thing"></a><strong>One more thing</strong></h3><p>写作本文时，有让图片并排显示的需求，而网页默认是每个图片后自动换行。</p>
<p>解决：<br>使用 <code>&lt;img&gt;</code> HTML标签的 <code>style</code> 属性来覆盖图片的 “块 “行为，形如：</p>
<div class="highlight-container" data-rel="Html"><figure class="iseeu highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/uploads/image-1.jpg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;image-1&quot;</span> <span class="attr">style</span>=<span class="string">&quot;display: inline-block&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;/uploads/image-2.jpg&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;image-2&quot;</span> <span class="attr">style</span>=<span class="string">&quot;display: inline-block&quot;</span> /&gt;</span></span><br></pre></td></tr></table></figure></div>



<h3 id="引用："><a href="#引用：" class="headerlink" title="引用："></a><strong>引用</strong>：</h3><ul>
<li><a class="link"   href="https://github.com/litten/hexo-theme-yilia/issues/801#issuecomment-456317331" >长链接不会自动换行解决方案 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://yolkpie.net/2021/09/14/CSS%E6%96%87%E6%9C%AC%E6%BA%A2%E5%87%BA%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" >CSS文本溢出解决方案 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://github.com/iissnan/hexo-theme-next/issues/1139#issuecomment-286639102" >网页图片并排显示解决方案 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop环境配置</title>
    <url>/2024/01/10/Hadoop%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="主要步骤"><a href="#主要步骤" class="headerlink" title="主要步骤"></a>主要步骤</h2><h3 id="一、准备虚拟机"><a href="#一、准备虚拟机" class="headerlink" title="一、准备虚拟机"></a>一、准备虚拟机</h3><p>首先要创建五台一模一样的Ubuntu虚拟机，可在VMware中先安装一个Ubuntu虚拟机，然后克隆出另外四个虚拟机。</p>
<h3 id="二、搭建集群"><a href="#二、搭建集群" class="headerlink" title="二、搭建集群"></a>二、搭建集群</h3><h4 id="1-修改hostname"><a href="#1-修改hostname" class="headerlink" title="1.修改hostname"></a>1.修改hostname</h4><p>现在有五台虚拟机，改hostname：将其中一台改作master，其余分别改作slave1、slave2、slave3、slave4。让其处于同一局域网中。</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/hostname</span><br></pre></td></tr></table></figure></div>

<p>修改后保存。</p>
<h4 id="2-记录五台虚拟机的IP地址"><a href="#2-记录五台虚拟机的IP地址" class="headerlink" title="2.记录五台虚拟机的IP地址"></a>2.记录五台虚拟机的IP地址</h4><p>在终端输入<code>ipconfig</code>，可以得到本节点IP。最终可以得到：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.242.129	master</span><br><span class="line">192.168.242.130	slave1</span><br><span class="line">192.168.242.131	slave2</span><br><span class="line">192.168.242.132	slave3</span><br><span class="line">192.168.242.133	slave4</span><br></pre></td></tr></table></figure></div>

<p>接下来修改节点IP映射，在每台虚拟机的<code>hosts</code>文件末尾添加上述<code>IP-主机名</code>映射（重启后生效）：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/hosts  </span><br></pre></td></tr></table></figure></div>

<h4 id="3-ping通五台虚拟机"><a href="#3-ping通五台虚拟机" class="headerlink" title="3.ping通五台虚拟机"></a>3.ping通五台虚拟机</h4><p>利用刚刚记录下来的IP地址，五台虚拟机互相ping通：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">ping IP地址/主机名</span><br></pre></td></tr></table></figure></div>

<h4 id="4-配置SSH免密登录"><a href="#4-配置SSH免密登录" class="headerlink" title="4.配置SSH免密登录"></a>4.配置SSH免密登录</h4><p>首先安装SSH：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install openssh-server  #安装服务，一路回车                     </span><br><span class="line">sudo /etc/init.d/ssh restart  #启动服务                                      </span><br><span class="line">sudo ufw disable   #关闭防火墙     </span><br></pre></td></tr></table></figure></div>

<p>关闭完防火墙，接下来查看是否开通SSH服务：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">ps -e | grep ssh</span><br></pre></td></tr></table></figure></div>

<p>只要出现了以下进程就说明成功了：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/18/arKLqu23wdTIgbD.png"
                     
                ></p>
<p>接下来在master节点生成SSH公钥，公钥储存在 <code>/root/.ssh</code> 中</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">sudo cd /root/.ssh  </span><br><span class="line">rm ./id_rsa*            # 删除之前生成的公匙（如果有）                  </span><br><span class="line">ssh-keygen -t rsa       # 一直按回车就可以     </span><br></pre></td></tr></table></figure></div>

<p>让master 节点可以无密码 SSH 本机，在 master 节点上执行以下代码：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">cat ./id_rsa.pub &gt;&gt; ./authorized_keys</span><br></pre></td></tr></table></figure></div>

<p>完成后可执行<code>ssh master</code>验证一下（需要输入 <code>yes</code>，成功后执行 <code>exit</code> 返回原来的终端）</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">ssh master</span><br></pre></td></tr></table></figure></div>

<p>接着在 master 节点将上述公匙传输到 slave1 节点，过程中需要输入 slave1 节点的密码，传输100%以后就是传过去了：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">scp ./.ssh/id_rsa.pub xpk@slave1:/home/xpk</span><br></pre></td></tr></table></figure></div>

<p> 接着在 slave1 节点上，把 master 节点的公钥加入授权：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir ~/.ssh        # 如果不存在该文件夹需先创建，若已存在则忽略        </span><br><span class="line">cat ~/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys                                   </span><br><span class="line">rm ~/id_rsa.pub    # 用完就可以删掉了</span><br></pre></td></tr></table></figure></div>

<p>在其余 slave 节点重复以上步骤，然后就可以免密码SSH所有 slave 节点了：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/10/18/2NYJbqB8ytKh3zZ.png"
                     
                ></p>
<p>最后在 master 节点修改SSH文件权限（否则之后SSH免密登录可能失效）：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">chmod 700 /root/.ssh/	#修改 .ssh/ 文件夹权限为700</span><br><span class="line">chmod 600 /root/.ssh/authorized_keys 	#修改 authorized_keys 文件权限为700</span><br></pre></td></tr></table></figure></div>

<h4 id="5-安装配置JDK环境变量"><a href="#5-安装配置JDK环境变量" class="headerlink" title="5.安装配置JDK环境变量"></a>5.安装配置JDK环境变量</h4><h5 id="下载JDK"><a href="#下载JDK" class="headerlink" title="下载JDK"></a>下载JDK</h5><p>官网： <a class="link"   href="https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html" >https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>我下载的是 JDK1.8 ，压缩文件名为<code>jdk-8u391-linux-x64.tar.gz</code>。</p>
<h5 id="解压tar包"><a href="#解压tar包" class="headerlink" title="解压tar包"></a>解压tar包</h5><p>把安装包放到 <code>/usr/local/java/</code> 目录下面（没有java目录的话自行创建），然后解压安装包：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">创建目录</span></span><br><span class="line">mkdir -p /usr/local/java/	</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">解压</span></span><br><span class="line">tar -zxvf  安装包名称	</span><br></pre></td></tr></table></figure></div>

<h5 id="配置JDK环境变量"><a href="#配置JDK环境变量" class="headerlink" title="配置JDK环境变量"></a>配置JDK环境变量</h5><p>修改 environment 文件：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改文件</span></span><br><span class="line">sudo gedit /etc/environment</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件尾部添加如下配置</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">java</span></span><br><span class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_391</span><br><span class="line">export JRE_HOME=/usr/local/java/jdk1.8.0_391/jre</span><br><span class="line">export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib</span><br></pre></td></tr></table></figure></div>

<p>修改 profile 文件：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">修改文件</span></span><br><span class="line">sudo gedit /etc/profile </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件尾部添加如下配置</span></span><br><span class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_391</span><br><span class="line">export JRE_HOME=/usr/local/java/jdk1.8.0_391/jre</span><br><span class="line">export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib</span><br><span class="line">export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH:$HOME/bin</span><br></pre></td></tr></table></figure></div>

<p>配置立即生效：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">立即生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></div>

<p>检查Java命令：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">查看java版本</span></span><br><span class="line">java -version</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">显示如下表示成功</span></span><br><span class="line">java version &quot;1.8.0_391&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_391-b13)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.391-b13, mixed mode)</span><br></pre></td></tr></table></figure></div>

<h4 id="6-安装和配置Hadoop"><a href="#6-安装和配置Hadoop" class="headerlink" title="6.安装和配置Hadoop"></a>6.安装和配置Hadoop</h4><h5 id="下载Hadoop安装包"><a href="#下载Hadoop安装包" class="headerlink" title="下载Hadoop安装包"></a>下载Hadoop安装包</h5><p>Hadoop官网：<a class="link"   href="http://hadoop.apache.org/" >http://hadoop.apache.org/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>我下载的是 hadoop3 ，压缩文件名为<code>hadoop-3.3.6.tar.gz</code>。</p>
<h5 id="解压Hadoop安装包（只在master做）"><a href="#解压Hadoop安装包（只在master做）" class="headerlink" title="解压Hadoop安装包（只在master做）"></a>解压Hadoop安装包（只在master做）</h5><p>把 Hadoop 压缩包放置到<code>/opt/hadoop</code>目录内，然后在 master 主机上执行以下代码：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/hadoop</span><br></pre></td></tr></table></figure></div>

<p>进入<code>/opt/hadoop</code>目录后，执行解压缩命令：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf hadoop-3.3.6.tar.gz</span><br></pre></td></tr></table></figure></div>

<h5 id="配置env文件（只在master做）"><a href="#配置env文件（只在master做）" class="headerlink" title="配置env文件（只在master做）"></a>配置env文件（只在master做）</h5><p>执行命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /opt/hadoop/hadoop/etc/hadoop/hadoop-env.sh</span><br></pre></td></tr></table></figure></div>

<p>找到<code>export JAVA_HOME</code>这行，修改为：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/local/java/jdk1.8.0_391/</span><br></pre></td></tr></table></figure></div>

<h5 id="配置核心组件文件（只在master做）"><a href="#配置核心组件文件（只在master做）" class="headerlink" title="配置核心组件文件（只在master做）"></a>配置核心组件文件（只在master做）</h5><p>Hadoop 的核心组件文件是<code>core-site.xml</code>，位于<code>/opt/hadoop/hadoop/etc/hadoop</code>子目录下，将下面的配置代码放在文件的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间。</p>
<p>执行编辑<code>core-site.xml</code>文件的命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /opt/hadoop/hadoop/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure></div>

<p>需要在<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间加入的代码：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;/opt/hadoop/hadoopdata&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>

<p>编辑完成后，退出并保存即可。</p>
<h5 id="配置文件系统（只在master做）"><a href="#配置文件系统（只在master做）" class="headerlink" title="配置文件系统（只在master做）"></a>配置文件系统（只在master做）</h5><p>Hadoop 的文件系统配置文件是<code>hdfs-site.xml</code>，位于<code>/opt/hadoop/hadoop/etc/hadoop</code>子目录下，将以下代码放在文件的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间。</p>
<p>执行编辑<code>hdfs-site.xml</code>文件的命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /opt/hadoop/hadoop/etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure></div>

<p>需要在<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间加入的代码：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>

<p>编辑完成后，退出保存即可。</p>
<h5 id="配置yarn-site-xml文件（只在master做）"><a href="#配置yarn-site-xml文件（只在master做）" class="headerlink" title="配置yarn-site.xml文件（只在master做）"></a>配置yarn-site.xml文件（只在master做）</h5><p>yarn 的站点配置文件是<code>yarn-site.xml</code>，位于<code>/opt/hadoop/hadoop/etc/hadoop</code>子目录下，将以下代码放在文件的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间。</p>
<p>执行编辑<code>yarn-site.xml</code>文件的命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /opt/hadoop/hadoop/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure></div>

<p>需要在<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间加入的代码：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;master:18040&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;master:18030&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;master:18025&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;master:18141&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;master:18088&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>

<h5 id="配置MapReduce计算框架文件（只在master做）"><a href="#配置MapReduce计算框架文件（只在master做）" class="headerlink" title="配置MapReduce计算框架文件（只在master做）"></a>配置MapReduce计算框架文件（只在master做）</h5><p>配置文件是<code>mapred-site.xml</code>，在<code>/opt/hadoop/hadoop/etc/hadoop</code>子目录下，将下面的代码填充到文件的<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间。</p>
<p>执行命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /opt/hadoop/hadoop/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure></div>

<p>需要在<code>&lt;configuration&gt;</code>和<code>&lt;/configuration&gt;</code>之间加入的代码：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">		&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></div>

<p>编辑完毕，保存退出即可。</p>
<h5 id="配置master的workers文件（只在master做）"><a href="#配置master的workers文件（只在master做）" class="headerlink" title="配置master的workers文件（只在master做）"></a>配置master的workers文件（只在master做）</h5><p>workers 文件给出了 Hadoop 集群的 slave 节点列表，该文件十分重要，因为启动 Hadoop 的时候，系统总是根据当前workers 文件中的 slave 节点名称列表启动集群，不在列表中的 slave 节点便不会被视为计算节点。</p>
<p>执行编辑 workers 文件命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /opt/hadoop/hadoop/etc/hadoop/workers</span><br></pre></td></tr></table></figure></div>

<p>加入以下代码：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br><span class="line">slave4</span><br></pre></td></tr></table></figure></div>

<p>注意：删除 workers 文件中原来 localhost 那一行。</p>
<h5 id="复制master上的Hadoop到slave节点（只在master做）"><a href="#复制master上的Hadoop到slave节点（只在master做）" class="headerlink" title="复制master上的Hadoop到slave节点（只在master做）"></a>复制master上的Hadoop到slave节点（只在master做）</h5><p>通过复制master节点上的 Hadoop ，能够大大提高系统部署效率。由于我这里有4个 slave 节点，所以复制4次。</p>
<p>复制命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">scp -r /opt/hadoop root@slave1:/opt</span><br><span class="line">scp -r /opt/hadoop root@slave2:/opt</span><br><span class="line">scp -r /opt/hadoop root@slave3:/opt</span><br><span class="line">scp -r /opt/hadoop root@slave4:/opt</span><br></pre></td></tr></table></figure></div>

<h5 id="配置操作系统环境变量（五个节点都做）"><a href="#配置操作系统环境变量（五个节点都做）" class="headerlink" title="配置操作系统环境变量（五个节点都做）"></a>配置操作系统环境变量（五个节点都做）</h5><p>回到用户目录命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/hadoop</span><br></pre></td></tr></table></figure></div>

<p>然后编辑<code>.bash_profile</code>文件，命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit ~/.bash_profile</span><br></pre></td></tr></table></figure></div>

<p>最后把以下代码追加到文件的尾部：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#HADOOP</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/hadoop/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></div>

<p>保存退出后，执行命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bash_profile</span><br></pre></td></tr></table></figure></div>

<p><code>source ~/.bash_profile</code>命令是使上述配置生效。</p>
<p>提示：在其余 slave 节点使用上述相同的配置方法，配置全部 slave 节点。</p>
<h5 id="创建Hadoop数据目录（只在master做）"><a href="#创建Hadoop数据目录（只在master做）" class="headerlink" title="创建Hadoop数据目录（只在master做）"></a>创建Hadoop数据目录（只在master做）</h5><p>创建数据目录，命令是：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/hadoop/hadoopdata</span><br></pre></td></tr></table></figure></div>

<h5 id="格式化文件系统（只在master做）"><a href="#格式化文件系统（只在master做）" class="headerlink" title="格式化文件系统（只在master做）"></a>格式化文件系统（只在master做）</h5><p>执行格式化文件系统命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure></div>

<h3 id="三、Hadoop集群的启动与关闭"><a href="#三、Hadoop集群的启动与关闭" class="headerlink" title="三、Hadoop集群的启动与关闭"></a>三、Hadoop集群的启动与关闭</h3><h4 id="1-启动和关闭Hadoop集群（只在master做）"><a href="#1-启动和关闭Hadoop集群（只在master做）" class="headerlink" title="1.启动和关闭Hadoop集群（只在master做）"></a>1.启动和关闭Hadoop集群（只在master做）</h4><p>首先进入安装主目录，命令是：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/hadoop/hadoop/sbin</span><br></pre></td></tr></table></figure></div>

<p>然后启动，命令是：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">./start-all.sh</span><br></pre></td></tr></table></figure></div>

<p>如果要关闭 Hadoop 集群，可以使用命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">./stop-all.sh</span><br></pre></td></tr></table></figure></div>

<h4 id="2-验证Hadoop集群是否启动成功"><a href="#2-验证Hadoop集群是否启动成功" class="headerlink" title="2.验证Hadoop集群是否启动成功"></a>2.验证Hadoop集群是否启动成功</h4><p>在 master 节点的浏览器中输入<code>localhost:9870/</code>并回车。打开 HDFS 面板查看详细信息：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/10/PHrsxtvNiIFGmkT.png"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/10/x4uYlirEd5U2hgy.png"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/10/zUywuYjHvRTX3sa.png"
                     
                ></p>
<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p><a class="link"   href="https://blog.csdn.net/weixin_52105111/article/details/123159877" >三台Ubuntu虚拟机搭建 Hadoop集群 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://blog.51cto.com/u_12835254/5273118" >Linux：Ubuntu配置jdk环境变量 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><a class="link"   href="https://blog.csdn.net/weixin_44198965/article/details/89603788?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164601575316780271530136%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=164601575316780271530136&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-89603788.pc_search_result_cache&utm_term=hadoop%E5%AE%89%E8%A3%85&spm=1018.2226.3001.4187" >Hadoop安装与配置详细教程 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h2 id="遇到的-问题-解决方法"><a href="#遇到的-问题-解决方法" class="headerlink" title="遇到的 问题&amp;解决方法"></a>遇到的 问题&amp;解决方法</h2><h3 id="一、部分Ubuntu虚拟机无法连接网络"><a href="#一、部分Ubuntu虚拟机无法连接网络" class="headerlink" title="一、部分Ubuntu虚拟机无法连接网络"></a>一、部分Ubuntu虚拟机无法连接网络</h3><h4 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h4><p>安装之后可以正常使用，但是隔了一段时间再上就发现有一两台虚拟机连不上网络。</p>
<h4 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h4><div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo service NetworkManager stop</span><br><span class="line">sudo <span class="built_in">rm</span> /var/lib/NetworkManager/NetworkManager.state</span><br><span class="line">sudo service NetworkManager start</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/NetworkManager/NetworkManager.conf	<span class="comment">#把false改成true</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo service NetworkManager restart</span><br></pre></td></tr></table></figure></div>

<h4 id="参考资料：-1"><a href="#参考资料：-1" class="headerlink" title="参考资料："></a>参考资料：</h4><p><a class="link"   href="https://blog.csdn.net/lj695242104/article/details/80922108" >ubuntu 18.04 网络图标不见的问题解决方案 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="二、第一次运行Hadoop时，出现以下报错："><a href="#二、第一次运行Hadoop时，出现以下报错：" class="headerlink" title="二、第一次运行Hadoop时，出现以下报错："></a>二、第一次运行Hadoop时，出现以下报错：</h3><div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">ERROR: Attempting to operate on hdfs namenode as root</span><br><span class="line">ERROR: but there is no HDFS_NAMENODE_USER defined. </span><br><span class="line">Aborting operation.</span><br><span class="line">Starting datanodes</span><br><span class="line">ERROR: Attempting to operate on hdfs datanode as root</span><br><span class="line">ERROR: but there is no HDFS_DATANODE_USER defined. </span><br><span class="line">Aborting operation.</span><br><span class="line">Starting secondary namenodes</span><br><span class="line">ERROR: Attempting to operate on hdfs secondarynamenode as root</span><br><span class="line">ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. </span><br><span class="line">Aborting operation.</span><br></pre></td></tr></table></figure></div>

<h4 id="解决：-1"><a href="#解决：-1" class="headerlink" title="解决："></a>解决：</h4><p>在<code>$HADOOP_HOME/etc/hadoop/hadoop-env.sh</code>中添加以下内容：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure></div>

<h4 id="参考资料：-2"><a href="#参考资料：-2" class="headerlink" title="参考资料："></a>参考资料：</h4><p><a class="link"   href="https://stackoverflow.com/questions/48129029/hdfs-namenode-user-hdfs-datanode-user-hdfs-secondarynamenode-user-not-defined" >HDFS_NAMENODE_USER, HDFS_DATANODE_USER &amp; HDFS_SECONDARYNAMENODE_USER not defined <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="三、主节点启动成功，从节点没有启动"><a href="#三、主节点启动成功，从节点没有启动" class="headerlink" title="三、主节点启动成功，从节点没有启动"></a>三、主节点启动成功，从节点没有启动</h3><h4 id="解决：-2"><a href="#解决：-2" class="headerlink" title="解决："></a>解决：</h4><p>执行编辑 workers 文件命令：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">sudo gedit /opt/hadoop/hadoop/etc/hadoop/workers</span><br></pre></td></tr></table></figure></div>

<p>加入以下代码：</p>
<div class="highlight-container" data-rel="Sh"><figure class="iseeu highlight sh"><table><tr><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line">slave3</span><br><span class="line">slave4</span><br></pre></td></tr></table></figure></div>

<h4 id="原因分析："><a href="#原因分析：" class="headerlink" title="原因分析："></a>原因分析：</h4><p>网上教程用的是Hadoop 2 版本，配置 slave 节点列表文件时修改的是<code>slaves</code>文件；而我使用的是 Hadoop 3 版本，Hadoop 3 版本里的配置文件需要修改<code>workers</code>文件，而不是<code>slaves</code>文件。</p>
<h4 id="参考资料：-3"><a href="#参考资料：-3" class="headerlink" title="参考资料："></a>参考资料：</h4><p><a class="link"   href="https://blog.51cto.com/u_16099172/6391674" >hadoop从节点进程缺失 hadoop从节点没有启动 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce配置与操作</title>
    <url>/2024/01/11/MapReduce%E9%85%8D%E7%BD%AE%E4%B8%8E%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="一、通过eclipse连接hadoop"><a href="#一、通过eclipse连接hadoop" class="headerlink" title="一、通过eclipse连接hadoop"></a>一、通过eclipse连接hadoop</h3><h4 id="1-主要步骤"><a href="#1-主要步骤" class="headerlink" title="1. 主要步骤"></a>1. 主要步骤</h4><ul>
<li><p>安装eclipse</p>
</li>
<li><p>安装Hadoop-Eclipse-Plugin</p>
</li>
<li><p>配置Hadoop-Eclipse-Plugin</p>
</li>
</ul>
<p>参考资料已给出此部分详细步骤，因此此处不再展开，仅给出实现效果如下：</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/17/5e8bfMxDjoOsPVL.png"
                      alt="image-20231117144850544" style="zoom: 67%;" 
                >

<h4 id="2-参考资料"><a href="#2-参考资料" class="headerlink" title="2. 参考资料"></a>2. 参考资料</h4><ul>
<li><a class="link"   href="https://blog.csdn.net/u010185220/article/details/79095179" >windows10上使用Eclipse配置Hadoop开发环境详细步骤+WordCount示例 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<h4 id="3-遇到的问题"><a href="#3-遇到的问题" class="headerlink" title="3. 遇到的问题"></a>3. 遇到的问题</h4><ul>
<li><h5 id="新添加的插件在Eclipse中不显示"><a href="#新添加的插件在Eclipse中不显示" class="headerlink" title="新添加的插件在Eclipse中不显示"></a>新添加的插件在Eclipse中不显示</h5><ul>
<li><p>解决方法</p>
<p>在 <code>eclipse/configuration</code> 目录下的 <code>config.ini</code> 文件中加入一行 : <code>osgi.checkConfiguration=true</code>，这样它就会寻找并安装插件。</p>
</li>
<li><p>参考资料</p>
<p><a class="link"   href="https://blog.csdn.net/qq_38789941/article/details/86244990" >Eclipse 安装插件后不显示的解决办法 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
</li>
</ul>
</li>
</ul>
<h3 id="二、WordCount示例"><a href="#二、WordCount示例" class="headerlink" title="二、WordCount示例"></a>二、WordCount示例</h3><h4 id="1-主要步骤-1"><a href="#1-主要步骤-1" class="headerlink" title="1. 主要步骤"></a>1. 主要步骤</h4><p>参考资料已给出此部分详细步骤，因此此处仅列举出主要步骤。</p>
<ul>
<li><p>新建项目</p>
</li>
<li><p>在项目的src目录下创建<code>WordCount.java</code>类，内容如下：</p>
<div class="highlight-container" data-rel="Java"><figure class="iseeu highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> Package;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> &#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Object, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">word</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">itr</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString());</span><br><span class="line">            <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">                word.set(itr.nextToken());</span><br><span class="line">                context.write(word, one);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">IntSumReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span><br><span class="line">                <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">                sum += val.get();</span><br><span class="line">            &#125;</span><br><span class="line">            result.set(sum);</span><br><span class="line">            context.write(key, result);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> <span class="title class_">GenericOptionsParser</span>(conf, args).getRemainingArgs();</span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Usage: wordcount &lt;in&gt; &lt;out&gt;&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@SuppressWarnings(&quot;deprecation&quot;)</span></span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Job</span>(conf, <span class="string">&quot;word count&quot;</span>);</span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line">        job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">        job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">        job.setReducerClass(IntSumReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(otherArgs[<span class="number">1</span>]));</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="literal">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>在项目的src目录下创建<code>log4j.properties</code>文件，内容如下：</p>
<div class="highlight-container" data-rel="Properties"><figure class="iseeu highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Configure logging for testing:optionally with log file </span></span><br><span class="line"><span class="comment">#log4j.rootLogger=debug,appender </span></span><br><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">info,appender </span></span><br><span class="line"><span class="comment">#log4j.rootLogger=error,appender </span></span><br><span class="line"><span class="comment">#\u8F93\u51FA\u5230\u63A7\u5236\u53F0 </span></span><br><span class="line"><span class="attr">log4j.appender.appender</span>=<span class="string">org.apache.log4j.ConsoleAppender </span></span><br><span class="line"><span class="comment">#\u6837\u5F0F\u4E3ATTCCLayout </span></span><br><span class="line"><span class="attr">log4j.appender.appender.layout</span>=<span class="string">org.apache.log4j.TTCCLayout</span></span><br></pre></td></tr></table></figure></div>
</li>
<li><p>配置运行参数</p>
</li>
<li><p>运行</p>
</li>
</ul>
<h4 id="2-运行结果"><a href="#2-运行结果" class="headerlink" title="2. 运行结果"></a>2. 运行结果</h4><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/17/o6ERhliMpC85qPm.png"
                      alt="image-20231117160047360"
                ></p>
<p>其中，<code>word.txt</code> 文件内容如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">a</span><br><span class="line">a</span><br><span class="line">a</span><br><span class="line"></span><br><span class="line">b</span><br><span class="line">b</span><br><span class="line">b</span><br><span class="line"></span><br><span class="line">c</span><br><span class="line">c</span><br><span class="line">c</span><br><span class="line"></span><br><span class="line">d</span><br><span class="line">e</span><br><span class="line">f</span><br><span class="line"></span><br><span class="line">hello hadoop !</span><br><span class="line">hello world !</span><br></pre></td></tr></table></figure></div>

<p>程序输出 <code>hdfs://192.168.242.129:9000/hadoop-user/output.txt/part-r-00000</code> 文件内容如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="code"><pre><span class="line">!	2</span><br><span class="line">a	3</span><br><span class="line">b	3</span><br><span class="line">c	3</span><br><span class="line">d	1</span><br><span class="line">e	1</span><br><span class="line">f	1</span><br><span class="line">hadoop	1</span><br><span class="line">hello	2</span><br><span class="line">world	1</span><br></pre></td></tr></table></figure></div>

<p>词频统计结果无误。</p>
<h4 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3. 参考资料"></a>3. 参考资料</h4><ul>
<li><a class="link"   href="https://cwiki.apache.org/confluence/display/HADOOP2/WordCount" >WordCount Example <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
<li><a class="link"   href="https://blog.csdn.net/u010185220/article/details/79095179" >windows10上使用Eclipse配置Hadoop开发环境详细步骤+WordCount示例 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<h4 id="4-遇到的问题"><a href="#4-遇到的问题" class="headerlink" title="4. 遇到的问题"></a>4. 遇到的问题</h4><ul>
<li><h5 id="环境变量问题"><a href="#环境变量问题" class="headerlink" title="环境变量问题"></a>环境变量问题</h5><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.</span><br></pre></td></tr></table></figure></div>

<ul>
<li>问题分析</li>
</ul>
<p>从错误信息中可以看到，Hadoop在执行<code>Shell.getWinUtilsPath</code>的时候抛出了异常。这是因为Hadoop在进行某些本地文件系统操作时，依赖于一些环境变量，其中包括<code>HADOOP_HOME</code>。这两个变量都没有被正确设置，导致了<code>FileNotFoundException</code>。</p>
<ul>
<li><p>解决方法</p>
<p>在项目运行配置中指定<code>HADOOP_HOME</code>环境变量及其值：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2023/11/17/3dmlWo9A8LMwkSU.png"
                      alt="image-20231117161245048"
                ></p>
</li>
<li><p>参考资料</p>
<ul>
<li><a class="link"   href="https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems" >Problems running Hadoop on Windows <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
</li>
</ul>
</li>
<li><h5 id="权限错误问题"><a href="#权限错误问题" class="headerlink" title="权限错误问题"></a>权限错误问题</h5><div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">[Thread-5] WARN org.apache.hadoop.mapred.LocalJobRunner - job_local2147375942_0001</span><br><span class="line">org.apache.hadoop.security.AccessControlException: Permission denied: user=23876, access=WRITE, inode=&quot;/hadoop-user&quot;:root:supergroup:drwxr-xr-x</span><br><span class="line">[main] INFO org.apache.hadoop.mapreduce.Job - Job job_local2147375942_0001 failed with state FAILED due to: NA</span><br></pre></td></tr></table></figure></div>

<ul>
<li><p>问题分析</p>
<p>这个错误表明在本地运行作业时，用户尝试写入目录<code>/hadoop-user</code>时遇到权限问题，并导致作业以失败结束。</p>
</li>
<li><p>解决方法</p>
<p>在master节点中执行以下代码，以赋予当前用户对目标HDFS文件夹的写权限：</p>
<div class="highlight-container" data-rel="Shell"><figure class="iseeu highlight shell"><table><tr><td class="code"><pre><span class="line">sudo chmod -R 777 /hadoop-user/</span><br></pre></td></tr></table></figure></div>
</li>
<li><p>参考资料</p>
<ul>
<li><p><a class="link"   href="https://hadoop.apache.org/docs/r1.0.4/cn/hdfs_permissions_guide.html#%E8%B6%85%E7%BA%A7%E7%94%A8%E6%88%B7" >HDFS权限管理用户指南 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
</li>
<li><p><a class="link"   href="https://www.cnblogs.com/yinzhengjie2020/p/13737254.html" >HDFS权限管理篇-博客园 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>高级数据库技术-复习</title>
    <url>/2024/01/13/%E9%AB%98%E7%BA%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%80%E6%9C%AF-%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<blockquote>
<p>文中PPT截图引用自：中国科学技术大学 金培权老师</p>
</blockquote>
<h2 id="第1章-数据库系统概述"><a href="#第1章-数据库系统概述" class="headerlink" title="第1章 数据库系统概述"></a>第1章 数据库系统概述</h2><p>1、DBMS系统结构组成</p>
<p>2、数据库、DBMS、数据库系统</p>
<h2 id="第2章-关系数据库技术回顾"><a href="#第2章-关系数据库技术回顾" class="headerlink" title="第2章 关系数据库技术回顾"></a><strong>第2章</strong> 关系数据库技术回顾</h2><p>1、数据模型和关系数据模型</p>
<p>2、SQL</p>
<p>3、三级模式结构与数据独立性</p>
<h2 id="第3章-数据库设计"><a href="#第3章-数据库设计" class="headerlink" title="第3章 数据库设计"></a>第3章 数据库设计</h2><p>1、函数依赖的概念</p>
<h3 id="2、最小函数依赖集"><a href="#2、最小函数依赖集" class="headerlink" title="2、最小函数依赖集"></a>2、最小函数依赖集</h3><ul>
<li><p>概念</p>
<ul>
<li>给定一个函数依赖集S，若能找到一个远小于S的等价函数依赖集T，则DBMS只要实现T就可实现S中的所有函数依赖</li>
</ul>
</li>
<li><p>计算</p>
<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/12/guaG4vcoVEZ93zW.png"
                      style="zoom: 48%;" 
                ></li>
</ul>
<h3 id="3、码的形式化定义"><a href="#3、码的形式化定义" class="headerlink" title="3、码的形式化定义"></a>3、码的形式化定义</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/12/iFlOsbpfnRj9Wu1.png"
                      style="zoom: 52.5%;" 
                >

<h3 id="4、1NF、2NF、3NF、BCNF"><a href="#4、1NF、2NF、3NF、BCNF" class="headerlink" title="4、1NF、2NF、3NF、BCNF"></a>4、1NF、2NF、3NF、BCNF</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/12/C9gFc6RbdsK7Grj.png"
                      style="zoom:50.8%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/12/X6iHbLD79UI34J8.png"
                      style="zoom:51.6%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/12/sz5AnZ3jVyCgWio.png"
                      style="zoom:51.5%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/12/6G2fnXJO8zgMQtm.png"
                      style="zoom:50.8%;" 
                >

<h3 id="5、无损并且保持函数依赖分解到3NF的算法"><a href="#5、无损并且保持函数依赖分解到3NF的算法" class="headerlink" title="5、无损并且保持函数依赖分解到3NF的算法"></a>5、无损并且保持函数依赖分解到3NF的算法</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/KeAMoWNk9RCcqPZ.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/lHpma8vq6D5X4Tz.png"
                      style="zoom:63.7%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/gy1EPABntiaLMF5.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/Nx1idoeMZhVzsJ7.png"
                      style="zoom:50.5%;" 
                >

<p>6、无损分解到BCNF的算法</p>
<p>7、数据库设计过程以及各个过程的主要工作</p>
<p>8、ER设计的基本方法</p>
<p>9、逻辑设计的主要工作</p>
<p>10、ER模型到关系模型的转换方法</p>
<h2 id="第4章-数据存储"><a href="#第4章-数据存储" class="headerlink" title="第4章 数据存储"></a>第4章 数据存储</h2><h3 id="1、磁盘块存取时间"><a href="#1、磁盘块存取时间" class="headerlink" title="1、磁盘块存取时间"></a>1、磁盘块存取时间</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/UVQIsu2Kh1TSaCW.png"
                      style="zoom:52.5%;" 
                >

<p>2、存储器结构</p>
<p>3、不同类型存储介质之间的差异</p>
<h2 id="第5章-数据表示"><a href="#第5章-数据表示" class="headerlink" title="第5章 数据表示"></a>第5章 数据表示</h2><p>1、数据项的表示</p>
<p>2、记录的表示</p>
<h3 id="3、记录在磁盘块中的组织"><a href="#3、记录在磁盘块中的组织" class="headerlink" title="3、记录在磁盘块中的组织"></a>3、记录在磁盘块中的组织</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/GgXKW5TmRq6y8L7.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/uRr3JNcLEhIiZzp.png"
                      style="zoom:51.5%;" 
                >

<h4 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/4xYgs2J38XHyFGD.png"
                      style="zoom: 45%;" 
                >

<h5 id="1、记录在块内的分隔"><a href="#1、记录在块内的分隔" class="headerlink" title="1、记录在块内的分隔"></a>1、记录在块内的分隔</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/6lEzecpShMLQC5F.png"
                      style="zoom:50%;" 
                >

<h5 id="2、跨块VS-不跨块"><a href="#2、跨块VS-不跨块" class="headerlink" title="2、跨块VS.不跨块"></a>2、跨块VS.不跨块</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/yWpSt6vBz8l7EXV.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/rOU4asCZyRNwPtA.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/YmDdrxPOVEsoH16.png"
                      style="zoom:50%;" 
                >

<h5 id="3、不同类型的记录聚簇"><a href="#3、不同类型的记录聚簇" class="headerlink" title="3、不同类型的记录聚簇"></a>3、不同类型的记录聚簇</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/vqrjVo5b73EO1yt.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/UnD26c1AMyQVfst.png"
                      style="zoom:50%;" 
                >

<h5 id="4、在块中按序存储记录"><a href="#4、在块中按序存储记录" class="headerlink" title="4、在块中按序存储记录"></a>4、在块中按序存储记录</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/NKBZuD1EtesknM6.png"
                      style="zoom:50%;" 
                >

<h5 id="5、记录的分裂"><a href="#5、记录的分裂" class="headerlink" title="5、记录的分裂"></a>5、记录的分裂</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/YQtKbDhrGOU9A1n.png"
                      style="zoom:50%;" 
                >

<h5 id="6、记录的地址"><a href="#6、记录的地址" class="headerlink" title="6、记录的地址"></a>6、记录的地址</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/1jEcXa2bTzi6qmr.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/a4gyFUMLpdczerS.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/9TGXmpjcdRxwIJL.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/BU8ZD4fletVKsOx.png"
                      style="zoom:50%;" 
                >

<h5 id="7、记录的修改"><a href="#7、记录的修改" class="headerlink" title="7、记录的修改"></a>7、记录的修改</h5><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/KqQDiuYlJBPLmHM.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/SUNQdTW3VbPDxlo.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/uOWGeRZLSmHyvp7.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/saUicFHQxVqdzt9.png"
                      style="zoom:50%;" 
                >

<p>4、链表式堆文件和目录式堆文件</p>
<h2 id="第6章-缓冲区管理"><a href="#第6章-缓冲区管理" class="headerlink" title="第6章 缓冲区管理"></a>第6章 缓冲区管理</h2><h3 id="1、缓冲区结构、frame-dirty-pin-count等概念的含义"><a href="#1、缓冲区结构、frame-dirty-pin-count等概念的含义" class="headerlink" title="1、缓冲区结构、frame&#x2F;dirty&#x2F;pin-count等概念的含义"></a>1、缓冲区结构、frame&#x2F;dirty&#x2F;pin-count等概念的含义</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/EwMrW3XBnmSgKil.png"
                      style="zoom:50%;" 
                >

<img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/XRrThE7dzVoM4ju.png"
                      style="zoom:50%;" 
                >

<h3 id="2、缓冲区置换算法"><a href="#2、缓冲区置换算法" class="headerlink" title="2、缓冲区置换算法"></a>2、缓冲区置换算法</h3><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/bUuFOtz3BjK1Qoa.png"
                      style="zoom:50%;" 
                >

<h4 id="0、OPT算法"><a href="#0、OPT算法" class="headerlink" title="0、OPT算法"></a>0、OPT算法</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/VY4v1X3HNmBMoqP.png"
                      style="zoom:50%;" 
                >

<h4 id="1、LRU算法"><a href="#1、LRU算法" class="headerlink" title="1、LRU算法"></a>1、LRU算法</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/5xkOZoqJ2a6vfcK.png"
                      style="zoom:50%;" 
                >

<h4 id="2、LRU-K算法"><a href="#2、LRU-K算法" class="headerlink" title="2、LRU-K算法"></a>2、LRU-K算法</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/Ysdpm7uVUkyHSIK.png"
                      style="zoom:50%;" 
                >

<h4 id="3、2Q算法"><a href="#3、2Q算法" class="headerlink" title="3、2Q算法"></a>3、2Q算法</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/ELuYHUPBlcJZams.png"
                      style="zoom:50%;" 
                >

<h4 id="4、Second-Chance-FIFO算法"><a href="#4、Second-Chance-FIFO算法" class="headerlink" title="4、Second-Chance FIFO算法"></a>4、Second-Chance FIFO算法</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/PWEJgNeZAXGrdz5.png"
                      style="zoom:50%;" 
                >

<h4 id="5、CLOCK算法"><a href="#5、CLOCK算法" class="headerlink" title="5、CLOCK算法"></a>5、CLOCK算法</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/Ax2lqY8WPk5mf1O.png"
                      style="zoom:50%;" 
                >

<h4 id="6、SSD上的置换算法"><a href="#6、SSD上的置换算法" class="headerlink" title="6、SSD上的置换算法"></a>6、SSD上的置换算法</h4><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2024/01/13/QEcRVfsdXuDyk6x.png"
                      style="zoom:50%;" 
                >

<p>3、缓冲区管理器的实现</p>
<h2 id="第7章-索引结构"><a href="#第7章-索引结构" class="headerlink" title="第7章 索引结构"></a>第7章 索引结构</h2><p>1、顺序文件上的索引：密集索引和稀疏索引</p>
<p>2、非顺序文件上的辅助索引</p>
<h3 id="3、散列表、动态散列"><a href="#3、散列表、动态散列" class="headerlink" title="3、散列表、动态散列"></a>3、散列表、动态散列</h3><h3 id="4、B-Tree"><a href="#4、B-Tree" class="headerlink" title="4、B+ Tree"></a>4、B+ Tree</h3>]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
</search>
